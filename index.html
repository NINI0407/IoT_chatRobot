<!DOCTYPE html>
<html lang="zh-Hant">
<head>
  <meta charset="UTF-8">
  <title>AI 視訊聊天 Demo</title>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <script src="https://kit.fontawesome.com/86e57103de.js" crossorigin="anonymous"></script>
  <style>
    body { font-family: sans-serif; text-align: center; }
    video { width: 320px; height: auto; border: 2px solid #ccc; margin-top: 1em; }
    #chatbox { margin-top: 20px; }
  </style>
</head>
<body>
  <h1><i class="fa-solid fa-video" style="color: #FFD43B;"></i>    AI 視訊聊天</h1>
  
  <video id="video" autoplay muted></video>
  <div id="chatbox">
    <p><strong>你說：</strong><span id="user-speech"></span></p>
    <p><strong></strong><span id="ai-response"></span></p>
    <button id="start-btn" style="width: 50px;height: 50px; font-size: 30px;"><i class="fa-solid fa-face-smile"></i></button>
  </div>

  <script>
    window.addEventListener('DOMContentLoaded', () => {
      const video = document.getElementById('video');
      const aiResponse = document.getElementById('ai-response');
      const userSpeech = document.getElementById('user-speech');
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      const recognition = new SpeechRecognition();
      recognition.lang = 'zh-TW';
      recognition.interimResults = false;
      recognition.continuous = false;
      let isFaceRecognitionFinish = false;
      let isAISpeaking = false;
      let lastDetection = null;

      const GEMINI_API_KEY = "AIzaSyARJQzxRRNGEmK-WKx1f3egCypJEFqsK9E";

      navigator.mediaDevices.getUserMedia({ video: true })
        .then(stream => video.srcObject = stream)
        .catch(err => console.error('無法開啟鏡頭', err));

      Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri('/models/face-api.js-models/tiny_face_detector'),
        faceapi.nets.ageGenderNet.loadFromUri('/models/face-api.js-models/age_gender_model'),
        faceapi.nets.faceExpressionNet.loadFromUri('/models/face-api.js-models/face_expression'),
        faceapi.nets.faceLandmark68Net.loadFromUri('/models/face-api.js-models/face_landmark_68')
      ]).then(startDetection);

      let isClick = false;
      function clickdown(){
        const btn = document.getElementById('start-btn');
        isClick = !isClick;
        btn.innerHTML = isClick
          ? '<i class="fa-solid fa-face-grin-tongue-squint"></i>'
          : '<i class="fa-solid fa-face-smile"></i>';

        if (isClick) {
          startListening();  // 呼叫你語音辨識的函式
        }
        
      }
      document.getElementById('start-btn').addEventListener('click', clickdown);

      function translateExpression(expr) {
        const map = {
          happy: '開心', sad: '難過', angry: '生氣', surprised: '驚訝', neutral: '很無語', fearful: '害怕', disgusted: '厭惡'
        };
        return map[expr] || expr;
      }

      function getFaceShape(landmarks) {
        const jaw = landmarks.getJawOutline();
        const left = jaw[0];
        const right = jaw[jaw.length - 1];
        const chin = jaw[Math.floor(jaw.length / 2)];
        const faceWidth = Math.abs(right.x - left.x);
        const faceHeight = Math.abs(chin.y - jaw[0].y);
        const ratio = faceWidth / faceHeight;
        if (ratio > 1.05) return '圓形臉';
        if (ratio < 0.8) return '長形臉';
        return '瓜子臉';
      }

      let isSpoken = false;
      async function startDetection() {
        if (isAISpeaking) return;
        const options = new faceapi.TinyFaceDetectorOptions();
        setInterval(async () => {
          const result = await faceapi.detectSingleFace(video, options)
            .withFaceLandmarks()
            .withAgeAndGender()
            .withFaceExpressions();

          if (result && !isSpoken) {
            lastDetection = result;
            const { age, gender, expressions } = result;
            const topExpr = Object.entries(expressions).reduce((a, b) => a[1] > b[1] ? a : b)[0];
            const prompt = `根據下列資訊：一位大約 ${Math.round(age)} 歲的 ${gender === 'male' ? '男性' : '女性'}，臉部表情看起來是 ${translateExpression(topExpr)}，請用一句親切自然的中文跟他打招呼，並說出他的特徵資訊，15個字內的回答，不要說出實際年齡，如果判斷出來是小於20歲的女生，叫他美眉，大於20歲則叫紫嘖，如果判斷出來是小於20歲的男生，叫他底迪，大於20歲則叫叔叔。`;
            isSpoken = true;
            isFaceRecognitionFinish = true;
            fetchGemini(prompt);
          }
        }, 5000);
      }

      function analyzeFacialProportions(landmarks) {
        const leftEye = landmarks.getLeftEye();
        const rightEye = landmarks.getRightEye();
        const nose = landmarks.getNose();
        const mouth = landmarks.getMouth();

        const eyeDistance = distance(center(leftEye), center(rightEye));
        const noseToMouth = distance(center(nose), center(mouth));
        const eyeToMouth = distance(center(leftEye), center(mouth));

        return {
          eyeDistance: Math.round(eyeDistance),
          noseToMouth: Math.round(noseToMouth),
          eyeToMouth: Math.round(eyeToMouth),
          proportionSummary: `兩眼距離約${Math.round(eyeDistance)}px，鼻子到嘴巴距離約${Math.round(noseToMouth)}px`
        };
      }

      function center(points) {
        const x = points.reduce((sum, pt) => sum + pt.x, 0) / points.length;
        const y = points.reduce((sum, pt) => sum + pt.y, 0) / points.length;
        return { x, y };
      }

      function distance(p1, p2) {
        return Math.sqrt((p1.x - p2.x) ** 2 + (p1.y - p2.y) ** 2);
      }

      function getSkinToneFromFace(video, detection) {
        if(video.readyState > 2){
          const canvas = document.createElement('canvas');
          const ctx = canvas.getContext('2d');
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

          const { x, y, width, height } = detection.detection.box;
          const faceCenterX = x + width / 2;
          const faceCenterY = y + height / 2;

          const skinData = ctx.getImageData(faceCenterX - 10, faceCenterY - 10, 20, 20).data;
          let r = 0, g = 0, b = 0, count = 0;
          for (let i = 0; i < skinData.length; i += 4) {
            r += skinData[i];
            g += skinData[i + 1];
            b += skinData[i + 2];
            count++;
          }
          r = Math.round(r / count);
          g = Math.round(g / count);
          b = Math.round(b / count);

          return `膚色 RGB(${r},${g},${b})`;
        }
      }


      async function fetchGemini(prompt) {
        if (!GEMINI_API_KEY) {
          aiResponse.textContent = "錯誤：請設定 Gemini API Key。";
          return;
        }

        try {
          const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${GEMINI_API_KEY}`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ contents: [{ parts: [{ text: prompt }] }] })
          });

          const data = await response.json();
          const reply = data.candidates?.[0]?.content?.parts?.[0]?.text || '無回應';
          aiResponse.textContent = reply;
          speak(reply);
        } catch (error) {
          aiResponse.textContent = "AI 回應失敗，請檢查網路或 API 設定。";
        }
      }

      function startListening() {
        recognition.start();
      }

      recognition.addEventListener('result', event => {
        const transcript = event.results[0][0].transcript;
        userSpeech.textContent = transcript;

        if (/妝容|穿搭|外貌|顏值|建議|評分/.test(transcript) && lastDetection) {
          const faceShape = getFaceShape(lastDetection.landmarks);
          const age = Math.round(lastDetection.age);
          const gender = lastDetection.gender === 'male' ? '男性' : '女性';
          const tone = getSkinToneFromFace(video, lastDetection);
          const proportions = analyzeFacialProportions(lastDetection.landmarks);
          const needsRating = transcript.includes("幫我評分") || transcript.includes("好不好看");

          let prompt = '';
          if (needsRating) {
            prompt = `根據以下特徵請給出此人的顏值1到10分打分數，並簡短說明打分原因，可以語氣犀利像朋友一樣。此人為${age}歲${gender}，臉型為${faceShape}，${proportions.proportionSummary}，${getSkinToneFromFace}。請用中文回答，15字內評語，顏值以 1~10 分數開頭，不要提到數據。`;
          } else {
            prompt = `根據下列資訊評估此人的外貌特徵並給予穿搭或妝容建議。可以語氣犀利搞笑機車像朋友一樣。資訊如下：${age}歲${gender}，臉型為${faceShape}，${proportions.proportionSummary}，${tone}。請用中文回答，先簡短評價外貌，再提供建議，總長不超過80字，不要提到數，。`;
          }

          fetchGemini(prompt);
        } else {
          fetchGemini(transcript + '。口氣可以搞笑機車一點，用一句話回答。');
        }
      });

      recognition.addEventListener('end', () => {
        console.log('語音辨識結束');
      });

      // let voices = [];
      // let voicesLoaded = false;

      // window.speechSynthesis.onvoiceschanged = () => {
      //   voices = window.speechSynthesis.getVoices();
      //   voicesLoaded = true;
      // };

      function speak(text) {
        // if (!voicesLoaded) {
        //   setTimeout(() => speak(text), 500);
        //   return;
        // }
        const synth = window.speechSynthesis;
        const utter = new SpeechSynthesisUtterance(text);
        utter.lang = 'zh-TW';
        // const voice = synth.getVoices().find(v => v.lang === 'zh-TW' && v.name.includes('Google'));
        // if (voice) utter.voice = voice;
        utter.onend = () => {
          isAISpeaking = false;
          startListening();
        };
        // synth.cancel();
        synth.speak(utter);
      }

    });
  </script>
</body>
</html>
