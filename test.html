
//判斷臉型
function getFaceShape(landmarks) {
  const jaw = landmarks.getJawOutline();
  const left = jaw[0];
  const right = jaw[jaw.length - 1];
  const chin = jaw[Math.floor(jaw.length / 2)];
  const faceWidth = Math.abs(right.x - left.x);
  const faceHeight = Math.abs(chin.y - jaw[0].y);
  const ratio = faceWidth / faceHeight;
  if (ratio > 1.05) return '圓形臉';
  if (ratio < 0.8) return '長形臉';
  return '瓜子臉';
}

//判斷臉部特徵
function analyzeFacialProportions(landmarks) {
  const leftEye = landmarks.getLeftEye();
  const rightEye = landmarks.getRightEye();
  const nose = landmarks.getNose();
  const mouth = landmarks.getMouth();

  const eyeDistance = distance(center(leftEye), center(rightEye));
  const noseToMouth = distance(center(nose), center(mouth));
  const eyeToMouth = distance(center(leftEye), center(mouth));

  return {
    eyeDistance: Math.round(eyeDistance),
    noseToMouth: Math.round(noseToMouth),
    eyeToMouth: Math.round(eyeToMouth),
    proportionSummary: `兩眼距離約${Math.round(eyeDistance)}px，
                      鼻子到嘴巴距離約${Math.round(noseToMouth)}px`
  };
}

//判斷膚色
function getSkinToneFromFace(video, detection) {
  if(video.readyState > 2){
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d');
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    const { x, y, width, height } = detection.detection.box;
    const faceCenterX = x + width / 2;
    const faceCenterY = y + height / 2;

    const skinData = ctx.getImageData(faceCenterX - 10, faceCenterY - 10, 20, 20).data;
    let r = 0, g = 0, b = 0, count = 0;
    for (let i = 0; i < skinData.length; i += 4) {
      r += skinData[i];
      g += skinData[i + 1];
      b += skinData[i + 2];
      count++;
    }
    r = Math.round(r / count);
    g = Math.round(g / count);
    b = Math.round(b / count);

    return `膚色 RGB(${r},${g},${b})`;
  }
}

async function fetchGemini(prompt) {
  if (!GEMINI_API_KEY) {
    aiResponse.textContent = "錯誤：請設定 Gemini API Key。";
    return;
  }

  try {
    const response = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:
      generateContent?key=${GEMINI_API_KEY}`, 
    {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ contents: [{ parts: [{ text: prompt }] }] })
    });

    const data = await response.json();
    const reply = data.candidates?.[0]?.content?.parts?.[0]?.text || '無回應';
    aiResponse.textContent = reply;
    speak(reply);
  } catch (error) {
    aiResponse.textContent = "AI 回應失敗，請檢查網路或 API 設定。";
  }
}

function startListening() {
  recognition.start();
}

recognition.addEventListener('result', event => {
  const transcript = event.results[0][0].transcript;
  userSpeech.textContent = transcript;

  if (/妝容|穿搭|外貌|顏值|建議|評分/.test(transcript) && lastDetection) {
    const faceShape = getFaceShape(lastDetection.landmarks);
    const age = Math.round(lastDetection.age);
    const gender = lastDetection.gender === 'male' ? '男性' : '女性';
    const tone = getSkinToneFromFace(video, lastDetection);
    const proportions = analyzeFacialProportions(lastDetection.landmarks);
    const needsRating = transcript.includes("幫我評分") || 
                        transcript.includes("好不好看");

    let prompt = '';
    if (needsRating) {
      prompt = `根據以下特徵請給出此人的顏值1到10分打分數，並簡短說明打分原因，
                可以語氣搞笑像朋友一樣。此人為${age}歲${gender}，臉型為${faceShape}，
                ${proportions.proportionSummary}，
                ${getSkinToneFromFace}。請用中文回答，15字內評語，顏值以 1~10 
                分數開頭，不要提到數據。`;
    } else {
      prompt = `根據下列資訊評估此人的外貌特徵並給予穿搭或妝容建議。可以語氣犀利搞笑像朋友一樣。
                資訊如下：${age}歲${gender}，臉型為${faceShape}，
                ${proportions.proportionSummary}，${tone}。
                請用中文回答，先簡短評價外貌，再提供建議，總長不超過80字，不要提到數，。`;
    }

    fetchGemini(prompt);
  } else {
    fetchGemini(transcript + '。口氣可以搞笑一點，用一句話回答。');
  }
});

recognition.addEventListener('end', () => {
  console.log('語音辨識結束');
});